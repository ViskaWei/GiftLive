#!/usr/bin/env python3
"""
LightGBM ä¿®å¤å®éªŒï¼šç¦ç”¨ Early Stopping + LambdaRank
===================================================

ä¿®å¤åŸå®éªŒçš„é—®é¢˜ï¼š
1. Early stopping ç¬¬ 1 è½®å°±åœäº†ï¼ˆBest iteration = 1ï¼‰
2. ç”¨ MAE åš early stopping åœ¨ 98.5% ä¸º 0 çš„æ•°æ®ä¸Šä¼šè¯¯å¯¼

å®éªŒå˜ä½“ï¼š
1. LightGBM (no early stop) - å¼ºåˆ¶è·‘å®Œ 500 æ£µæ ‘
2. LightGBM (LambdaRank) - ç”¨æ’åºæŸå¤±å‡½æ•°

Author: Viska Wei
Date: 2026-01-18
"""

import sys
sys.path.insert(0, '/home/swei20/GiftLive')

import numpy as np
import pandas as pd
import lightgbm as lgb
from sklearn.linear_model import Ridge
from scipy.stats import spearmanr
import json
from pathlib import Path
from datetime import datetime

from gift_EVpred.data_utils import prepare_dataset, get_feature_columns

# =============================================================================
# è¯„ä¼°å‡½æ•°
# =============================================================================
def revenue_capture_at_k(y_true, y_pred, k=0.01):
    """è®¡ç®— Revenue Capture @k%"""
    n_top = int(len(y_true) * k)
    if n_top == 0:
        n_top = 1
    top_indices = np.argsort(y_pred)[-n_top:]
    total_revenue = y_true.sum()
    if total_revenue == 0:
        return 0.0
    return y_true[top_indices].sum() / total_revenue

def gift_rate_at_k(y_true, y_pred, k=0.01):
    """è®¡ç®— Gift Rate @k%"""
    n_top = int(len(y_true) * k)
    if n_top == 0:
        n_top = 1
    top_indices = np.argsort(y_pred)[-n_top:]
    return (y_true[top_indices] > 0).mean()

def evaluate_model(y_true, y_pred, name="Model"):
    """è¯„ä¼°æ¨¡å‹"""
    results = {
        'name': name,
        'rev_cap_0.01': revenue_capture_at_k(y_true, y_pred, 0.01),
        'rev_cap_0.05': revenue_capture_at_k(y_true, y_pred, 0.05),
        'rev_cap_0.10': revenue_capture_at_k(y_true, y_pred, 0.10),
        'gift_rate_0.01': gift_rate_at_k(y_true, y_pred, 0.01),
        'gift_rate_0.05': gift_rate_at_k(y_true, y_pred, 0.05),
        'spearman': spearmanr(y_true, y_pred)[0],
    }
    return results

def print_results(results, baseline_rev_cap=None):
    """æ‰“å°ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {results['name']}")
    print(f"{'='*60}")
    print(f"  RevCap@1%:  {results['rev_cap_0.01']*100:.2f}%", end="")
    if baseline_rev_cap:
        diff = (results['rev_cap_0.01'] - baseline_rev_cap) / baseline_rev_cap * 100
        print(f"  ({diff:+.2f}% vs Ridge)")
    else:
        print()
    print(f"  RevCap@5%:  {results['rev_cap_0.05']*100:.2f}%")
    print(f"  RevCap@10%: {results['rev_cap_0.10']*100:.2f}%")
    print(f"  GiftRate@1%: {results['gift_rate_0.01']*100:.2f}%")
    print(f"  Spearman:   {results['spearman']:.4f}")

# =============================================================================
# ä¸»å®éªŒ
# =============================================================================
def main():
    print("="*60)
    print("ğŸƒ LightGBM ä¿®å¤å®éªŒï¼šç¦ç”¨ Early Stopping + LambdaRank")
    print("="*60)

    # åŠ è½½æ•°æ®
    print("\nğŸ“¦ Loading data...")
    train_df, val_df, test_df = prepare_dataset()
    feature_cols = get_feature_columns(train_df)

    print(f"  Train: {len(train_df):,}")
    print(f"  Val:   {len(val_df):,}")
    print(f"  Test:  {len(test_df):,}")
    print(f"  Features: {len(feature_cols)}")

    # å‡†å¤‡æ•°æ®
    X_train = train_df[feature_cols].values
    y_train = train_df['target_raw'].values
    X_val = val_df[feature_cols].values
    y_val = val_df['target_raw'].values
    X_test = test_df[feature_cols].values
    y_test = test_df['target_raw'].values

    all_results = {}

    # =========================================================================
    # Baseline: Ridge
    # =========================================================================
    print("\n" + "="*60)
    print("ğŸ”µ Training Ridge (Baseline)...")
    print("="*60)

    ridge = Ridge(alpha=1.0)
    ridge.fit(X_train, y_train)
    ridge_pred = ridge.predict(X_test)

    ridge_results = evaluate_model(y_test, ridge_pred, "Ridge (Baseline)")
    print_results(ridge_results)
    all_results['ridge'] = ridge_results
    baseline_rev_cap = ridge_results['rev_cap_0.01']

    # =========================================================================
    # Exp 1: LightGBM ç¦ç”¨ Early Stopping
    # =========================================================================
    print("\n" + "="*60)
    print("ğŸŸ¢ Training LightGBM (No Early Stopping, 500 trees)...")
    print("="*60)

    params_no_es = {
        'objective': 'regression',
        'metric': 'mae',
        'n_estimators': 500,
        'max_depth': 8,
        'learning_rate': 0.05,
        'num_leaves': 64,
        'min_child_samples': 100,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 0.1,
        'seed': 42,
        'verbose': -1,
        'n_jobs': -1,
    }

    lgb_no_es = lgb.LGBMRegressor(**params_no_es)
    # ä¸ä¼  eval_set å’Œ callbacksï¼Œå¼ºåˆ¶è·‘å®Œæ‰€æœ‰æ ‘
    lgb_no_es.fit(X_train, y_train)
    lgb_no_es_pred = lgb_no_es.predict(X_test)

    lgb_no_es_results = evaluate_model(y_test, lgb_no_es_pred, "LightGBM (No Early Stop, 500 trees)")
    print_results(lgb_no_es_results, baseline_rev_cap)
    all_results['lgb_no_early_stop'] = lgb_no_es_results

    # ç‰¹å¾é‡è¦æ€§
    importance = lgb_no_es.feature_importances_
    importance_df = pd.DataFrame({
        'feature': feature_cols,
        'importance': importance
    }).sort_values('importance', ascending=False)
    print("\nğŸ“Š Top 10 Feature Importance:")
    print(importance_df.head(10).to_string(index=False))

    # =========================================================================
    # Exp 2: LightGBM LambdaRank (æŒ‰ streamer åˆ†ç»„)
    # =========================================================================
    print("\n" + "="*60)
    print("ğŸŸ¡ Training LightGBM (LambdaRank, 500 trees)...")
    print("="*60)

    # ä¸º LambdaRank å‡†å¤‡ group ä¿¡æ¯ - æŒ‰ streamer_id åˆ†ç»„
    # æ¯ä¸ªä¸»æ’­çš„è§‚ä¼—ä½œä¸ºä¸€ä¸ª query group
    train_df_sorted = train_df.sort_values('streamer_id').reset_index(drop=True)
    train_group = train_df_sorted.groupby('streamer_id').size().values.tolist()

    val_df_sorted = val_df.sort_values('streamer_id').reset_index(drop=True)
    val_group = val_df_sorted.groupby('streamer_id').size().values.tolist()

    X_train_rank = train_df_sorted[feature_cols].values
    # LambdaRank éœ€è¦ç¦»æ•£ç­‰çº§æ ‡ç­¾ (0-4)
    def to_relevance(y):
        """è½¬æ¢ä¸º 0-4 ç­‰çº§: 0=æ— , 1=å°é¢, 2=ä¸­é¢, 3=å¤§é¢, 4=whale"""
        rel = np.zeros(len(y), dtype=int)
        rel[y > 0] = 1      # ä»»ä½•æ‰“èµ
        rel[y > 10] = 2     # >10å…ƒ
        rel[y > 50] = 3     # >50å…ƒ
        rel[y > 100] = 4    # whale
        return rel

    y_train_rank = to_relevance(train_df_sorted['target_raw'].values)
    X_val_rank = val_df_sorted[feature_cols].values
    y_val_rank = to_relevance(val_df_sorted['target_raw'].values)

    print(f"  Train label dist: {np.bincount(y_train_rank)}")
    print(f"  Val label dist: {np.bincount(y_val_rank)}")

    print(f"  Train groups: {len(train_group)}, avg size: {np.mean(train_group):.1f}")
    print(f"  Val groups: {len(val_group)}, avg size: {np.mean(val_group):.1f}")

    params_rank = {
        'objective': 'lambdarank',
        'metric': 'ndcg',
        'max_depth': 8,
        'learning_rate': 0.05,
        'num_leaves': 64,
        'min_child_samples': 100,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'reg_alpha': 0.1,
        'reg_lambda': 0.1,
        'seed': 42,
        'verbose': -1,
        'n_jobs': -1,
        'lambdarank_truncation_level': 30,
    }

    # åˆ›å»º Dataset
    train_data = lgb.Dataset(X_train_rank, label=y_train_rank, group=train_group)
    val_data = lgb.Dataset(X_val_rank, label=y_val_rank, group=val_group, reference=train_data)

    # è®­ç»ƒ
    lgb_rank = lgb.train(
        params_rank,
        train_data,
        num_boost_round=500,
        valid_sets=[val_data],
        callbacks=[lgb.log_evaluation(100)],
    )
    lgb_rank_pred = lgb_rank.predict(X_test)

    lgb_rank_results = evaluate_model(y_test, lgb_rank_pred, "LightGBM (LambdaRank, 500 trees)")
    print_results(lgb_rank_results, baseline_rev_cap)
    all_results['lgb_lambdarank'] = lgb_rank_results

    # =========================================================================
    # æ±‡æ€»å¯¹æ¯”
    # =========================================================================
    print("\n" + "="*60)
    print("ğŸ“‹ æ±‡æ€»å¯¹æ¯”")
    print("="*60)

    print(f"\n{'Model':<40} {'RevCap@1%':>12} {'vs Ridge':>12}")
    print("-" * 64)
    for key, res in all_results.items():
        rev_cap = res['rev_cap_0.01'] * 100
        diff = (res['rev_cap_0.01'] - baseline_rev_cap) / baseline_rev_cap * 100
        print(f"{res['name']:<40} {rev_cap:>11.2f}% {diff:>+11.2f}%")

    # ä¿å­˜ç»“æœ
    output_path = Path("/home/swei20/GiftLive/gift_EVpred/results/lightgbm_fix_20260118.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
    save_results = {}
    for k, v in all_results.items():
        save_results[k] = {kk: float(vv) if isinstance(vv, (np.floating, float)) else vv
                          for kk, vv in v.items()}

    with open(output_path, 'w') as f:
        json.dump(save_results, f, indent=2)

    print(f"\nâœ… Results saved to {output_path}")

if __name__ == "__main__":
    main()
