# ğŸ¤– Coding Prompt Template: Gift EVpred

> **é€‚ç”¨èŒƒå›´**: æ‰€æœ‰ gift_EVpred å®éªŒ
> **ç‰ˆæœ¬**: 1.0
> **æœ€åæ›´æ–°**: 2026-01-18

---

## âš ï¸ å¼ºåˆ¶è§„åˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰

### æ•°æ®å¤„ç†è§„åˆ™

> **æ‰€æœ‰ gift_EVpred å®éªŒå¿…é¡»ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®å¤„ç†æ¨¡å—ï¼Œç¦æ­¢è‡ªè¡Œå®ç°æ•°æ®åŠ è½½å’Œç‰¹å¾æ„å»ºï¼**

```python
# âœ… æ­£ç¡®åšæ³•ï¼šä½¿ç”¨ç»Ÿä¸€æ¨¡å—
from gift_EVpred.data_utils import (
    prepare_dataset,
    get_feature_columns,
    verify_no_leakage,
    run_full_verification
)
from gift_EVpred.metrics import (
    evaluate_model,
    quick_eval,
    revenue_capture_at_k,
)

# æ ‡å‡†æ•°æ®å‡†å¤‡ï¼ˆ7-7-7 æŒ‰å¤©åˆ’åˆ†ï¼‰
train_df, val_df, test_df, lookups = prepare_dataset(
    train_days=7, val_days=7, test_days=7
)

# è·å–ç‰¹å¾åˆ—ï¼ˆè‡ªåŠ¨æ’é™¤æ³„æ¼ç‰¹å¾ï¼‰
feature_cols = get_feature_columns(train_df)

# âŒ ç¦æ­¢åšæ³•ï¼š
# - è‡ªè¡Œè¯»å– click.csv å¹¶æ„å»ºç‰¹å¾
# - ä½¿ç”¨ watch_live_time
# - ä½¿ç”¨ groupby().agg() è®¡ç®— pair/user/streamer ç»Ÿè®¡
# - è‡ªè¡Œå®ç°è¯„ä¼°æŒ‡æ ‡ï¼ˆå¿…é¡»ç”¨ metrics.pyï¼‰
```

### è¯„ä¼°æŒ‡æ ‡è§„åˆ™

> **æ‰€æœ‰è¯„ä¼°å¿…é¡»ä½¿ç”¨ `gift_EVpred/metrics.py`ï¼Œç¡®ä¿æŒ‡æ ‡ä¸€è‡´æ€§ï¼**

```python
# âœ… æ­£ç¡®åšæ³•ï¼šä½¿ç”¨ç»Ÿä¸€æŒ‡æ ‡æ¨¡å—
from gift_EVpred.metrics import evaluate_model, quick_eval

# å®Œæ•´è¯„ä¼°ï¼ˆæ¨èï¼‰
result = evaluate_model(y_true, y_pred, test_df)
print(result.summary())
result.to_json('gift_EVpred/results/exp_xxx.json')

# å¿«é€Ÿè¯„ä¼°ï¼ˆè®­ç»ƒä¸­ï¼‰
metrics = quick_eval(y_true, y_pred, whale_threshold=100)

# âŒ ç¦æ­¢åšæ³•ï¼š
# - è‡ªè¡Œè®¡ç®— RevCapã€Whale Recall ç­‰æŒ‡æ ‡
# - ä½¿ç”¨ sklearn metrics ä½œä¸ºä¸»æŒ‡æ ‡ï¼ˆå¦‚ MAEã€RMSEï¼‰
```

### ç¦æ­¢ä½¿ç”¨çš„ç‰¹å¾

| ç‰¹å¾ | åŸå›  | æ›¿ä»£æ–¹æ¡ˆ |
|------|------|---------|
| `watch_live_time` | ç»“æœæ³„æ¼ï¼ˆåŒ…å«æ‰“èµåæ—¶é—´ï¼‰ | ç§»é™¤ |
| `pair_gift_mean` (é _past) | æœªæ¥æ³„æ¼ | `pair_gift_mean_past` |
| `user_total_gift_7d` (é _past) | æœªæ¥æ³„æ¼ | `user_gift_sum_past` |

---

## ğŸ“‹ Coding Prompt æ¨¡æ¿

å¤åˆ¶ä»¥ä¸‹æ¨¡æ¿ï¼Œå¡«å†™ `[...]` éƒ¨åˆ†ï¼š

```markdown
# ğŸ¤– Coding Prompt: [å®éªŒåç§°]

> **Experiment ID:** `EXP-[YYYYMMDD]-gift_EVpred-[##]`
> **MVP:** MVP-X.X
> **Date:** YYYY-MM-DD
> **Author:** Viska Wei

---

## 1. ğŸ“Œ å®éªŒç›®æ ‡

**ä¸€å¥è¯**ï¼š[æœ¬å®éªŒè¦éªŒè¯ä»€ä¹ˆ]

**éªŒè¯å‡è®¾**ï¼šH[X.X] - [å‡è®¾å†…å®¹]

**é¢„æœŸç»“æœ**ï¼š
- è‹¥ [ç»“æœA] â†’ [ç»“è®ºA]
- è‹¥ [ç»“æœB] â†’ [ç»“è®ºB]

---

## 2. ğŸ§ª å®éªŒè®¾å®š

### 2.1 æ•°æ®ï¼ˆå¼ºåˆ¶ä½¿ç”¨ data_utilsï¼‰

```python
# âš ï¸ å¿…é¡»ä½¿ç”¨æ­¤æ–¹å¼åŠ è½½æ•°æ®
from gift_EVpred.data_utils import prepare_dataset, get_feature_columns

train_df, val_df, test_df, lookups = prepare_dataset(
    train_days=7,       # è®­ç»ƒé›†å¤©æ•°
    val_days=7,         # éªŒè¯é›†å¤©æ•°
    test_days=7,        # æµ‹è¯•é›†å¤©æ•°
    gap_days=0,         # gap å¤©æ•°ï¼ˆå¯é€‰ï¼‰
    label_window_hours=1  # æ ‡ç­¾çª—å£ï¼ˆå°æ—¶ï¼‰
)

feature_cols = get_feature_columns(train_df)
```

**æ•°æ®ä¿¡æ¯**ï¼š
```yaml
data:
  source: "KuaiLive"
  split: "7-7-7 by days"
  train_size: ~3.4M
  val_size: ~0.7M
  test_size: ~0.7M
  gift_rate: ~1.5%
  features: 40+
```

### 2.2 æ¨¡å‹

```yaml
model:
  name: "[æ¨¡å‹åç§°]"
  params:
    param1: value1
    param2: value2
```

### 2.3 è®­ç»ƒ

```yaml
training:
  seed: 42
  early_stopping: 50
  [å…¶ä»–å‚æ•°]
```

---

## 3. ğŸ“Š è¦ç”»çš„å›¾

| å›¾å· | å›¾è¡¨ç±»å‹ | Xè½´ | Yè½´ | ä¿å­˜è·¯å¾„ |
|------|---------|-----|-----|---------|
| Fig1 | [type] | [...] | [...] | `gift_EVpred/img/[name].png` |

**å›¾è¡¨è¦æ±‚**ï¼š
- æ‰€æœ‰æ–‡å­—è‹±æ–‡
- figsize: å•å¼  (6,5)ï¼Œå¤šå¼ æŒ‰ 6:5 æ‰©å¢
- åˆ†è¾¨ç‡ >= 300 dpi

---

## 4. ğŸ“ å‚è€ƒä»£ç 

| å‚è€ƒè„šæœ¬ | å¯å¤ç”¨ | éœ€ä¿®æ”¹ |
|---------|--------|--------|
| **gift_EVpred/data_utils.py** | `prepare_dataset()`, `get_feature_columns()` | âŒ ä¸è¦ä¿®æ”¹ |
| `scripts/xxx.py` | [...] | [...] |

---

## 5. ğŸ“ æœ€ç»ˆäº¤ä»˜ç‰©

### 5.1 å®éªŒæŠ¥å‘Š
- **è·¯å¾„**: `gift_EVpred/exp/exp_[name]_YYYYMMDD.md`
- **æ¨¡æ¿**: `_backend/template/exp.md`

### 5.2 å›¾è¡¨æ–‡ä»¶
- **è·¯å¾„**: `gift_EVpred/img/`
- **å‘½å**: `[descriptive_name].png`

### 5.3 æ•°å€¼ç»“æœ
- **è·¯å¾„**: `gift_EVpred/results/`
- **æ ¼å¼**: JSON

---

## 6. âš ï¸ æ£€æŸ¥æ¸…å•

### æ•°æ®å¤„ç†æ£€æŸ¥ï¼ˆå¿…é¡»é€šè¿‡ï¼‰
- [ ] ä½¿ç”¨ `prepare_dataset()` åŠ è½½æ•°æ®
- [ ] ä½¿ç”¨ `get_feature_columns()` è·å–ç‰¹å¾
- [ ] ç‰¹å¾åˆ—ä¸åŒ…å« `watch_live_time`
- [ ] æ‰€æœ‰ gift ç›¸å…³ç‰¹å¾å¸¦ `_past` åç¼€
- [ ] è¿è¡Œ `verify_no_leakage()` éªŒè¯é€šè¿‡

### æŒ‡æ ‡è¯„ä¼°æ£€æŸ¥ï¼ˆå¿…é¡»é€šè¿‡ï¼‰
- [ ] ä½¿ç”¨ `evaluate_model()` è¿›è¡Œå®Œæ•´è¯„ä¼°
- [ ] ä¸»æŒ‡æ ‡ä¸º `RevCap@1%`ï¼ˆä¸æ˜¯ MAE/RMSEï¼‰
- [ ] ç»“æœä¿å­˜åˆ° `gift_EVpred/results/` ç›®å½•
- [ ] è°ƒç”¨ `result.summary()` è¾“å‡ºå®Œæ•´æŠ¥å‘Š

### ä»£ç æ£€æŸ¥
- [ ] seed=42 å›ºå®šéšæœºæ€§
- [ ] å›¾è¡¨æ–‡å­—å…¨è‹±æ–‡
- [ ] ä¿å­˜æ—¥å¿—åˆ° `logs/`

---

## 7. ğŸ“¤ æŠ¥å‘ŠæŠ„é€

| ç›®æ ‡æ–‡ä»¶ | æ›´æ–°å†…å®¹ | ç« èŠ‚ |
|---------|---------|------|
| `gift_EVpred_roadmap.md` | MVP çŠ¶æ€ + ç»“è®ºå¿«ç…§ | Â§2.1, Â§4.3 |
| `gift_EVpred_hub.md` | å‡è®¾éªŒè¯çŠ¶æ€ + æ´è§ | Â§1, Â§4 |

---

<!--
ğŸ“Œ Agent æ‰§è¡Œè§„åˆ™ï¼š

1. âš ï¸ å¿…é¡»ä½¿ç”¨ gift_EVpred/data_utils.py åŠ è½½æ•°æ®
2. âš ï¸ å¿…é¡»ä½¿ç”¨ gift_EVpred/metrics.py è¯„ä¼°æ¨¡å‹
3. âŒ ç¦æ­¢è‡ªè¡Œå®ç°æ•°æ®å¤„ç†é€»è¾‘
4. âŒ ç¦æ­¢è‡ªè¡Œå®ç°è¯„ä¼°æŒ‡æ ‡
5. âŒ ç¦æ­¢ä½¿ç”¨ watch_live_time
6. âœ… å…ˆéªŒè¯æ•°æ®æ— æ³„æ¼å†è®­ç»ƒæ¨¡å‹
7. âœ… ä½¿ç”¨ evaluate_model() è¾“å‡ºå®Œæ•´è¯„ä¼°
8. âœ… æŒ‰æ¨¡æ¿è¾“å‡º exp.md æŠ¥å‘Š
-->
```

---

## ğŸ“¦ data_utils.py ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ç”¨æ³•

```python
#!/usr/bin/env python3
"""
Example: Using data_utils for gift EVpred experiment
"""
import sys
sys.path.insert(0, '/home/swei20/GiftLive')

from gift_EVpred.data_utils import (
    prepare_dataset,
    get_feature_columns,
    run_full_verification,
    load_raw_data
)
import lightgbm as lgb

# 1. å‡†å¤‡æ•°æ®ï¼ˆ7-7-7 åˆ’åˆ†ï¼Œæ— æ³„æ¼ï¼‰
train_df, val_df, test_df, lookups = prepare_dataset()

# 2. è·å–ç‰¹å¾åˆ—
feature_cols = get_feature_columns(train_df)
print(f"Features: {len(feature_cols)}")

# 3. éªŒè¯æ— æ³„æ¼ï¼ˆæ¨èï¼‰
gift, _, _, _, _ = load_raw_data()
run_full_verification(train_df, val_df, test_df, gift, feature_cols)

# 4. å‡†å¤‡è®­ç»ƒæ•°æ®
X_train = train_df[feature_cols]
y_train = train_df['target']  # log(1+gift)
X_val = val_df[feature_cols]
y_val = val_df['target']

# 5. è®­ç»ƒæ¨¡å‹
train_data = lgb.Dataset(X_train, label=y_train)
val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)

params = {
    'objective': 'regression',
    'metric': 'mae',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'seed': 42,
    'verbose': -1
}

model = lgb.train(
    params, train_data,
    num_boost_round=500,
    valid_sets=[train_data, val_data],
    callbacks=[lgb.early_stopping(50)]
)

# 6. è¯„ä¼°ï¼ˆå¿…é¡»ä½¿ç”¨ metrics æ¨¡å—ï¼‰
from gift_EVpred.metrics import evaluate_model

X_test = test_df[feature_cols]
y_pred = model.predict(X_test)
y_test = test_df['gift_amount']  # åŸå§‹é‡‘é¢ï¼ˆé logï¼‰

# å®Œæ•´è¯„ä¼°
result = evaluate_model(y_test, y_pred, test_df)
print(result.summary())

# ä¿å­˜ç»“æœ
result.to_json('gift_EVpred/results/exp_xxx.json')
```

### å¯ç”¨å‡½æ•°åˆ—è¡¨

#### data_utils.pyï¼ˆæ•°æ®å¤„ç†ï¼‰

| å‡½æ•° | ç”¨é€” |
|------|------|
| `prepare_dataset()` | å‡†å¤‡å®Œæ•´æ•°æ®é›†ï¼ˆä¸»å‡½æ•°ï¼‰ |
| `get_feature_columns(df)` | è·å–ç‰¹å¾åˆ—ï¼ˆæ’é™¤æ³„æ¼ç‰¹å¾ï¼‰ |
| `verify_no_leakage(df, gift)` | éªŒè¯ç‰¹å¾æ— æ³„æ¼ |
| `run_full_verification(...)` | è¿è¡Œå®Œæ•´éªŒè¯ |
| `load_raw_data()` | åŠ è½½åŸå§‹æ•°æ® |
| `split_by_days(df, ...)` | æŒ‰å¤©åˆ’åˆ†æ•°æ® |
| `create_frozen_lookups(gift, ts)` | åˆ›å»ºå†»ç»“ç‰¹å¾æŸ¥æ‰¾è¡¨ |
| `apply_frozen_features(df, lookups)` | åº”ç”¨å†»ç»“ç‰¹å¾ |

#### metrics.pyï¼ˆæŒ‡æ ‡è¯„ä¼°ï¼‰

| å‡½æ•° | ç”¨é€” |
|------|------|
| `evaluate_model(y_true, y_pred, test_df)` | å®Œæ•´æ¨¡å‹è¯„ä¼°ï¼ˆ**æ¨è**ï¼‰ |
| `quick_eval(y_true, y_pred)` | å¿«é€Ÿè¯„ä¼°ï¼ˆè®­ç»ƒä¸­ä½¿ç”¨ï¼‰ |
| `revenue_capture_at_k(y_true, y_pred, k)` | RevCap@K å•æŒ‡æ ‡ |
| `whale_recall_at_k(...)` | Whale Recall@K |
| `whale_precision_at_k(...)` | Whale Precision@K |
| `compute_revcap_curve(...)` | å¤š K å€¼ RevCap æ›²çº¿ |
| `compute_stability_by_day(...)` | æŒ‰å¤©ç¨³å®šæ€§è¯„ä¼° |
| `EvalResult` | ç»“æœç±»ï¼ˆæ”¯æŒ .summary()ã€.to_json()ï¼‰ |

---

## ğŸš« å¸¸è§é”™è¯¯

### é”™è¯¯ 1: è‡ªè¡Œè¯»å–æ•°æ®

```python
# âŒ é”™è¯¯
click = pd.read_csv('data/KuaiLive/click.csv')
gift = pd.read_csv('data/KuaiLive/gift.csv')
# ç„¶åè‡ªå·±åšç‰¹å¾...

# âœ… æ­£ç¡®
from gift_EVpred.data_utils import prepare_dataset
train_df, val_df, test_df, lookups = prepare_dataset()
```

### é”™è¯¯ 2: ä½¿ç”¨æ³„æ¼ç‰¹å¾

```python
# âŒ é”™è¯¯
features = ['watch_live_time', 'pair_gift_mean', ...]

# âœ… æ­£ç¡®
from gift_EVpred.data_utils import get_feature_columns
features = get_feature_columns(train_df)  # è‡ªåŠ¨æ’é™¤æ³„æ¼ç‰¹å¾
```

### é”™è¯¯ 3: è‡ªè¡Œè®¡ç®—èšåˆç‰¹å¾

```python
# âŒ é”™è¯¯ (ä¼šå¯¼è‡´æ³„æ¼)
pair_stats = gift.groupby(['user_id', 'streamer_id']).agg(...)
df = df.merge(pair_stats, ...)

# âœ… æ­£ç¡® (ä½¿ç”¨ data_utils æä¾›çš„ frozen ç‰¹å¾)
# ç‰¹å¾å·²ç»åœ¨ prepare_dataset() ä¸­è®¡ç®—å¥½äº†
```

### é”™è¯¯ 4: è‡ªè¡Œå®ç°è¯„ä¼°æŒ‡æ ‡

```python
# âŒ é”™è¯¯ï¼ˆè‡ªå·±ç®— RevCapï¼‰
def my_revcap(y_true, y_pred, k=0.01):
    top_k = int(len(y_true) * k)
    idx = np.argsort(y_pred)[-top_k:]
    return y_true[idx].sum() / y_true.sum()

# âŒ é”™è¯¯ï¼ˆç”¨ sklearn æŒ‡æ ‡ä½œä¸ºä¸»æŒ‡æ ‡ï¼‰
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_test, y_pred)  # ä¸æ˜¯ä¸šåŠ¡æŒ‡æ ‡

# âœ… æ­£ç¡®
from gift_EVpred.metrics import evaluate_model
result = evaluate_model(y_test, y_pred, test_df)
print(f"RevCap@1%: {result.revcap_1pct:.1%}")
```

---

> **è®°ä½**: ä½¿ç”¨ `data_utils.py` å’Œ `metrics.py` æ˜¯å¼ºåˆ¶è¦æ±‚ï¼Œä¸æ˜¯å»ºè®®ï¼
