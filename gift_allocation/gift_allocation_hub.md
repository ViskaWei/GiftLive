# 🧠 Gift Allocation Hub

> **Status:** 🔄 Phase 5 规划中 | **Layer:** 分配层 | **Date:** 2026-01-19

---

## 🔗 上游链接

| 层 | 链接 | 提供 |
|----|------|------|
| **Main** | [main_hub.md](../main/main_hub.md) | 全局综合、三层架构 |
| **Data** | [kuailive_hub.md](../KuaiLive/kuailive_hub.md) | 数据特性、EDA |
| **Estimate** | [gift_EVpred_hub.md](../gift_EVpred/gift_EVpred_hub.md) | EV 预测 baseline |

---

## 🎯 本层职责

> **分配层职责**：给定 EV 预测，如何分配高价值用户给主播，同时满足约束和维护生态？

```
┌─────────────────────────────────────────────────────────────┐
│                    gift_allocation 职责                      │
├─────────────────────────────────────────────────────────────┤
│ ✅ 做：分配策略、约束优化、Simulator、OPE 评估、生态指标     │
│ ❌ 不做：EV 预测模型训练、数据 EDA                           │
└─────────────────────────────────────────────────────────────┘
```

---

## 🔑 核心结论（分配层专属）

| # | 结论 | 证据 | 决策 |
|---|------|------|------|
| **K1** | **分配策略是最大杠杆** | Greedy 3x Random | 优化分配层 > 优化估计层 |
| **K2** | **凹收益分配无显著优势** | Δ=-1.17%, Gini改善-0.018 | 简化为 Greedy |
| **K3** | **软约束冷启动有效** | 收益+32%, 成功率+263% | 采用 λ=0.5 |
| **K4** | **SNIPS 是最佳 OPE 方法** | RelErr<10% | 探索率≥0.3, 日志≥5000 |
| **K5** | **高并发存在边际递减** | Revenue/User 下降 24.4% | 需考虑容量约束 |
| **K6** | **简单规则优于复杂框架** | Greedy+Rules +4.36% vs Shadow Price +2.74% | 保留 Greedy+软约束 |

### 推荐架构

| 组件 | 推荐方法 | 状态 |
|------|---------|------|
| **排序层** | EV 预测（来自 gift_EVpred） | ✅ RevCap@1%=51.4% |
| **分配层** | Greedy + 软约束 (λ=0.5) | ✅ 确认 |
| **评估层** | SNIPS OPE + Simulator V2 | ✅ 确认 |
| **风险层** | UCB/CVaR | ⏳ 待验证 |

---

## 📊 关键数字速查（分配层专属）

| 类别 | 指标 | 值 | 来源 |
|------|------|-----|------|
| **分配策略** | Greedy/Random 收益比 | **2.94x** | MVP-0.3 |
| | Concave vs Greedy Δ | -1.17% | MVP-2.1 |
| | Concave Gini 改善 | -0.018 | MVP-2.1 |
| **冷启动约束** | Soft Cold-Start Revenue Δ | **+32%** | MVP-2.2 |
| | Soft Cold-Start Success Δ | **+263%** | MVP-2.2 |
| | Hard Cold-Start Revenue Δ | -29% | MVP-2.2 |
| | 推荐 λ | **0.5** | MVP-2.2 |
| **OPE 评估** | SNIPS RelErr (Softmax) | 0.57% | MVP-3.1 |
| | SNIPS RelErr (Concave) | 4.31% | MVP-3.1 |
| | SNIPS RelErr (Greedy) | 9.97% | MVP-3.1 |
| | 最优探索率 | 0.3 | MVP-3.1 |
| | 最小日志量 | 5000+ | MVP-3.1 |
| **Simulator** | Gini 误差 | <5% | MVP-0.3 |
| | V2+ P50 误差 | 0% | MVP-4.1+ |
| | V2+ P90 误差 | 13.2% | MVP-4.1+ |
| | V2+ Mean 误差 | 24.0% | MVP-4.1+ |
| **并发容量** | Revenue/User 下降 | 24.4% | MVP-4.2 |
| | 拥挤率 @800 用户 | 67.9% | MVP-4.2 |
| | 推荐惩罚强度 β | 0.5 | MVP-4.2 |
| **影子价格** | Shadow Price Δ 收益 | +2.74% | MVP-5.2 |
| | Greedy+Rules Δ 收益 | **+4.36%** | MVP-5.2 |

### 数据/估计层数字（引用自上游）

> 以下数字来自上游节点，仅供参考

| 类别 | 指标 | 值 | 来源 |
|------|------|-----|------|
| **数据** | 打赏率 | 1.48% | [KuaiLive](../KuaiLive/kuailive_hub.md) |
| | User Gini | 0.942 | [KuaiLive](../KuaiLive/kuailive_hub.md) |
| | 延迟特性 | 86.3% delay=0 | [KuaiLive](../KuaiLive/kuailive_hub.md) |
| **估计** | RevCap@1% | **51.4%** | [gift_EVpred](../gift_EVpred/gift_EVpred_hub.md) |

---

## 🌲 核心问题树（分配层）

```
🌲 核心: 如何在全局最优下分配高价值用户？
│
├── Q1: 分配策略 - 如何平衡收益与公平？
│   ├── Q1.1: 凹收益 vs 贪心？ → ❌ Δ=-1.17%，无显著优势
│   ├── Q1.2: 边际递减系数如何设定？ → ❌ 模拟环境下影响不大
│   └── Q1.3: 冷启动/公平约束如何嵌入？ → ✅ 软约束：+32% 收益，+263% 成功率
│
├── Q2: 约束优化 - 如何处理多约束？
│   ├── Q2.1: 影子价格能否统一处理？ → ❌ FAIL (+2.74%<5%)
│   ├── Q2.2: 鲸鱼分散能否降低集中度？ → ⏳ 待验证
│   └── Q2.3: 羊群效应/攀比效应？ → ⏳ 待验证
│
├── Q3: 评估层 - 如何可靠评估策略？
│   ├── Q3.1: OPE 有效性？ → ✅ SNIPS 可用 (RelErr<10%)
│   ├── Q3.2: Simulator 可靠性？ → ✅ V2+ 金额校准 (P50=0%,Mean=27%)
│   │   └── 差距: 缺时序模型/忠诚度/Gini偏低 → V3 需求 (P2)
│   └── Q3.3: 评估窗口敏感性？ → ⏳ 待验证
│
└── Q4: 风险控制 - 如何降低上线风险？
    ├── Q4.1: 不确定性排序？ → ⏳ UCB/CVaR 待验证
    └── Q4.2: 多目标 Pareto 前沿？ → ⏳ 待验证

Legend: ✅ 已验证 | ❌ 已否定 | ⏳ 待验证
```

---

## 💡 洞见汇合（分配层专属）

| # | 洞见 | 观察 | 决策影响 | 证据 |
|---|------|------|---------|------|
| **I1** | Greedy 分配策略收益远高于 Random | 2.94x 差异 | 分配策略是核心杠杆 | MVP-0.3 |
| **I2** | Simulator Gini 可校准 | 误差<5% | 可用于策略相对比较 | MVP-0.3 |
| **I3** | 凹收益无显著优势但公平性改善 | Δ=-1.17%, Gini -0.018 | 简化为 Greedy+约束 | MVP-2.1 |
| **I4** | 软约束冷启动是 explore-exploit 平衡 | +32% 收益，+263% 成功率 | 冷启动约束是有价值的探索 | MVP-2.2 |
| **I5** | 硬约束过于激进 | -29% 收益 | 避免硬预留，用软约束 λ | MVP-2.2 |
| **I6** | V2+ 离散档位成功校准 | P50=0%, Mean=27% | Gate-4A PASS | MVP-4.1+ |
| **I7** | 高并发场景存在边际递减 | 24.4% 下降 | 分配策略需考虑容量约束 | MVP-4.2 |
| **I10** | **V2+ 仍缺失时序/忠诚度模型** | 时序:90%前10%，忠诚度:P50=100% | V3 需求（P2 优先级） | MVP-4.1+ |
| **I11** | V2+ User Gini 偏低 | 0.888 vs 真实 0.942 (-5.7%) | 鲸鱼效应模拟不足 | MVP-4.1+ |
| **I8** | 简单规则优于复杂框架 | +4.36% vs +2.74% | 现阶段 Greedy+Rules 足够 | MVP-5.2 |
| **I9** | 对偶变量收敛性差异大 | cold_start 好，whale_spread 差 | 约束惩罚函数设计很重要 | MVP-5.2 |

---

## ✅ Gate 状态

| Gate | 状态 | 结论 |
|------|------|------|
| Gate-2 分配层 | ✅ 关闭 | Greedy + 软约束冷启动 |
| Gate-3 评估层 | ✅ 关闭 | SNIPS RelErr<10% |
| Gate-4A 金额校准 | ✅ 通过 | V2+ 离散档位 |
| Gate-4B 并发容量 | ✅ 通过 | 边际递减建模 |
| Gate-5A 召回精排 | ❌ FAIL | 保留 Direct-only |
| Gate-5B 影子价格 | ❌ FAIL | 保留 Greedy+Rules |
| Gate-5C 鲸鱼分散 | ⏳ 待验证 | |
| Gate-5D 风险控制 | ⏳ 待验证 | |

---

## 🔴 决策空白

| DG | 问题 | 重要性 | 关闭条件 |
|----|------|--------|---------|
| **DG1** | 鲸鱼分散能否降低集中度？ | 解决马太效应 | 超载率<10% & Gini↓ |
| **DG2** | 不确定性排序能否降低波动？ | 上线稳定性 | CVaR@5% 改善 |
| **DG3** | 多目标 Pareto 前沿形状？ | 生态护栏定阈值 | 可解释权衡曲线 |

---

## 📐 设计原则（分配层）

### 已确认

| # | 原则 | 建议 | 证据 |
|---|------|------|------|
| P1 | 软约束优于硬约束 | ✅ 做 | MVP-2.2 |
| P2 | 金额模拟用离散档位 | ✅ 做 | MVP-4.1+ |
| P3 | 容量参数需按并发量校准 | ✅ 做 | MVP-4.2 |
| P4 | 高并发需考虑边际递减 | ✅ 做 | MVP-4.2 |
| P5 | 简单规则优于复杂框架（现阶段） | ✅ 做 | MVP-5.2 |

### 待验证

| # | 原则 | 初步建议 | 验证 Gate |
|---|------|---------|----------|
| P6 | 鲸鱼单独做匹配层 | 推荐 | Gate-5C |
| P7 | 上线初期用 LCB 保守排序 | 推荐 | Gate-5D |
| P8 | V3 需引入时序冲动模型 | P2 可选 | 如需精确模拟 |
| P9 | V3 需引入用户忠诚度模型 | P2 可选 | 如需精确模拟 |

### 已关闭方向

| 方向 | 证据 | 教训 |
|------|------|------|
| ~~凹收益替代 Greedy~~ | Δ=-1.17% | 边际递减需配合约束 |
| ~~影子价格统一框架~~ | +2.74%<5% | 简单规则更有效 |
| ~~召回-精排分工~~ | Coverage 5.5% | 需先保证召回覆盖率 |

---

## 📋 实验完成度

| Phase | 完成 | MVP |
|-------|------|-----|
| Phase 2 (分配策略) | 2/2 | 2.1 凹收益, 2.2 冷启动 |
| Phase 3 (评估层) | 1/1 | 3.1 OPE |
| Phase 4 (Simulator) | 2/2 | 4.1+ 金额, 4.2 容量 |
| Phase 5 (分配优化) | 2/5 | 5.1 ❌, 5.2 ❌ |

---

## 🚀 下一步

| 优先级 | MVP | 名称 | 目标 | Gate |
|--------|-----|------|------|------|
| 🟡 P1 | 5.3 | 鲸鱼分散 | 超载率<10%, Gini↓ | Gate-5C |
| 🟡 P1 | 5.4 | 风险控制 | CVaR@5% 改善 | Gate-5D |
| 🟢 P2 | 5.5 | 多目标生态调度 | Pareto 前沿 | - |

---

## 🔗 导航

| 文件 | 用途 |
|------|------|
| [main_hub.md](../main/main_hub.md) | 全局综合 |
| [gift_allocation_roadmap.md](./gift_allocation_roadmap.md) | MVP 规格、进度 |
| [exp/](./exp/) | 实验报告 |
| [results/](./results/) | 数值结果 JSON |

---

## 📎 附录：历史实验索引

> 以下实验已拆分到其他节点，仅保留引用

### 已迁移到 gift_EVpred

| 原 MVP | 内容 | 状态 |
|--------|------|------|
| MVP-0.2 | Baseline EV 模型 | ⚠️ 需重新验证（有泄漏） |
| MVP-1.1 | 两段式 vs 直接回归 | ⚠️ 需重新验证 |
| MVP-1.3 | 多任务学习 | ⚠️ 需重新验证 |
| MVP-1.4 | Oracle 分析 | ⚠️ 需重新验证 |

### 已迁移到 KuaiLive

| 原 MVP | 内容 | 状态 |
|--------|------|------|
| MVP-0.1 | 基础 EDA | ✅ |
| MVP-0.1-Enhanced | 全方位 EDA | ✅ |
| MVP-1.2 | 延迟审计 | ✅ 结论保留 |

---

## 更新日志

| 日期 | 变更 |
|------|------|
| 2026-01-09 | 创建，Phase 0-3 完成 |
| 2026-01-09 | 战略转向：从预测优化转向分配优化 |
| 2026-01-09 | MVP-5.1, 5.2 FAIL |
| 2026-01-19 | **重构**：拆分非分配层内容到 KuaiLive/gift_EVpred，精简职责边界 |
