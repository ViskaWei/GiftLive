# 🧠 Gift Allocation Hub

> **Status:** ✅ Phase 0-3 完成 | 🔄 Phase 4 进行中 (2/7) | **Data:** KuaiLive | **Date:** 2026-01-09

## 🔑 核心结论 (8条)

| # | 结论 | 证据 | 决策 |
|---|------|------|------|
| K1 | **直接回归优于两段式** | Top-1%: 54.5% vs 35.7% | 保留简单架构 |
| K2 | **延迟反馈不是问题** | 86.3%礼物立即发生 | 简单负例处理足够 |
| K3 | **凹收益分配无显著优势** | Δ=-1.17%, Gini改善-0.018 | 简化为Greedy |
| K4 | **软约束冷启动有效** | 收益+32%, 成功率+263% | 采用λ=0.5 |
| K5 | **多任务学习无优势** | Δ PR-AUC=-1.76pp | 保留单任务 |
| K6 | **Two-Stage适合精排** | gift子集Spearman=0.89 | 可用于召回-精排分工 |
| K7 | **交互历史是最强特征** | 重要性是第二名3倍 | 优先维护交互特征 |
| K8 | **SNIPS是最佳OPE方法** | RelErr<10% | 探索率≥0.3, 日志≥5000 |

## 🏗️ 推荐架构

| 层 | 方法 | 参数 | 性能 |
|----|------|------|------|
| **估计层** | Direct Regression (LightGBM) | log(1+Y) | Top-1%=54.5% |
| **分配层** | Greedy + 软约束冷启动 | λ=0.5, min_alloc=10 | 收益+32% |
| **评估层** | SNIPS OPE | ε≥0.3, N≥5000 | RelErr<10% |

## 📊 关键数字速查

| 类别 | 指标 | 值 | 来源 |
|------|------|-----|------|
| **数据特征** | 打赏率 (per-click) | 1.48% | MVP-0.1 |
| | 金额 P50/P90/P99 | 2/88/1,488 | MVP-0.1 |
| | 金额 Mean/Max | 82.7/56,246 | MVP-0.1 |
| | User Gini | 0.942 | MVP-0.1 |
| | Streamer Gini | 0.930 | MVP-0.1 |
| | Top 1% User贡献 | 59.9% | MVP-0.1 |
| | Matrix Density | 0.0064% | MVP-0.1 |
| | Cold Start Streamer | 92.2% | MVP-0.1 |
| **Baseline** | Top-1% Capture | 56.2% | MVP-0.2 |
| | Spearman | 0.891 | MVP-0.2 |
| | MAE(log) | 0.263 | MVP-0.2 |
| **公平对比** | Direct Top-1% (click全量) | 54.5% | MVP-1.1-fair |
| | Two-Stage Top-1% | 35.7% | MVP-1.1-fair |
| | Two-Stage NDCG@100 | 0.359 | MVP-1.1-fair |
| | Oracle_p 增益 | +54.9pp | MVP-1.4 |
| | Oracle_m 增益 | +3.1pp | MVP-1.4 |
| | Stage2 gift子集 Spearman | 0.892 | MVP-1.4 |
| **延迟建模** | 延迟中位数 | 0 秒 | MVP-1.2 |
| | 86.3%礼物立即发生 | delay=0 | MVP-1.2-audit |
| | pct_late_50 | 13.3% | MVP-1.2-audit |
| | Chapelle ECE改善 | -0.010 (变差) | MVP-1.2 |
| **多任务** | Single-Task PR-AUC | 0.182 | MVP-1.3 |
| | Multi-Task PR-AUC | 0.165 | MVP-1.3 |
| | Δ PR-AUC | -1.76pp | MVP-1.3 |
| **分配层** | Greedy/Random 收益比 | 2.94x | MVP-0.3 |
| | Concave vs Greedy Δ | -1.17% | MVP-2.1 |
| | Concave Gini改善 | -0.018 | MVP-2.1 |
| | Soft Cold-Start Revenue Δ | +32% | MVP-2.2 |
| | Soft Cold-Start Success Δ | +263% | MVP-2.2 |
| | Hard Cold-Start Revenue Δ | -29% | MVP-2.2 |
| | 推荐λ | 0.5 | MVP-2.2 |
| **评估层** | SNIPS RelErr (Softmax) | 0.57% | MVP-3.1 |
| | SNIPS RelErr (Concave) | 4.31% | MVP-3.1 |
| | SNIPS RelErr (Greedy) | 9.97% | MVP-3.1 |
| | 最优探索率 | 0.3 | MVP-3.1 |
| | 最小日志量 | 5000+ | MVP-3.1 |
| | Simulator Gini误差 | <5% | MVP-0.3 |
| **Simulator V2+** | V2+ P50误差 | 0% | MVP-4.1+ |
| | V2+ P90误差 | 13.2% | MVP-4.1+ |
| | V2+ P99误差 | 26.0% | MVP-4.1+ |
| | V2+ Mean误差 | 24.0% | MVP-4.1+ |
| | V2+ User Gini | 0.887 | MVP-4.1+ |
| **并发容量** | Revenue/User下降 | 24.4% | MVP-4.2 |
| | 拥挤率@800用户 | 67.9% | MVP-4.2 |
| | 容量约束收益差 | 2.2% | MVP-4.2 |
| | 推荐惩罚强度β | 0.5 | MVP-4.2 |

## 🌲 核心假设树

```
🌲 核心: 如何在直播场景下最大化全局打赏收益？
│
├── Q1: 估计层 - 如何准确预测极稀疏、重尾、延迟反馈的打赏行为？
│   ├── Q1.1: 两段式(是否打赏+金额)是否优于直接回归？ → ❌ 整体不优，但精排场景有优势
│   │   ├── H1: Stage2数据量/信息量不足 → ❌ 否定：Oracle_m增益仅+3.1pp
│   │   ├── H2: p×m乘法放大误差 → ❌ 否定：Stage1-only≈Two-Stage
│   │   ├── H3: Stage2 OOD问题 → ❌ 否定：gift子集Spearman=0.89
│   │   └── **主因**: ✅ Stage1分类不足（Oracle_p增益+54.9pp），推荐召回-精排分工
│   ├── Q1.2: 延迟反馈建模能否提升预测准确性？ → ❌ 审计通过，延迟不是问题
│   │   ├── ✅ 样本数差异已解释: 77,824 = gift×click配对（1.14x膨胀正常）
│   │   ├── ✅ pct_late_50=13.3%（代码bug已修复，之前单位错误）
│   │   └── ✅ 86.3%礼物delay=0，简单负例处理已足够
│   ├── Q1.3: 多任务学习能否用密集信号扶起稀疏信号？ → ❌ 无优势 (Δ=-1.76pp)
│   └── Q1.4: 重尾金额用log(1+Y)还是分位数回归？ → ⏳待验证
│
├── Q2: 决策层 - 如何在全局最优下分配高价值用户？
│   ├── Q2.1: 凹收益分配 vs 贪心分配的收益差异？ → ❌ Δ=-1.17%，无显著优势但公平性改善(Gini -0.018)
│   ├── Q2.2: 边际收益递减系数g'(V)如何设定/学习？ → ❌ 模拟环境下影响不大
│   ├── Q2.3: 冷启动/公平约束如何嵌入分配层？ → ✅ **软约束：收益+32%，成功率+263%**
│   └── Q2.4: 羊群效应/攀比效应是否存在？如何建模？ → ⏳待验证
│
└── Q3: 评估层 - 如何可靠评估分配策略？
    ├── Q3.1: OPE(IPS/DR)在高方差场景的有效性？ → ✅ **SNIPS可用，RelErr<10%，Gate-3关闭**
    │   ├── ✅ SNIPS最佳方法：Softmax 0.57%, Concave 4.31%, Greedy 9.97%
    │   ├── ❌ DR表现不如预期：Q函数偏差大于减少的方差
    │   └── ✅ 最优探索率~0.3，日志量≥5000
    ├── Q3.2: Simulator能否复现真实场景的关键特性？ → ✅ Gini可校准(<5%误差)，金额分布误差大
    │   ├── Q3.2.1: Simulator变量控制实验 - Two-Stage何时赢？ → ⏳ 待验证
    │   └── Q3.2.2: Simulator V2 能否修复金额分布失真？ → ✅ V2+ PASS (MVP-4.1+)
    │       ├── H4.1.1: 离散金额档位能否修复 P50/P90 误差？ → ✅ P50=0%, P90=23%
    │       ├── H4.1.2: V2+ 是否优于 V2 (lognormal+pareto)？ → ✅ Mean误差27% vs 375%
    │       └── H4.1.3: Gate-4A 通过？ → ✅ PASS → 继续 MVP-4.2
    │   └── Q3.2.3: 并发容量能否建模边际递减？ → ✅ PASS (MVP-4.2)
    │       ├── H4.2.1: Revenue/User 是否随负载下降？ → ✅ 24.4% 下降
    │       ├── H4.2.2: 拥挤率是否显著？ → ✅ 67.9% @800用户
    │       └── H4.2.3: Gate-4B 通过？ → ✅ PASS → 继续 MVP-4.3
    └── Q3.3: 评估窗口H如何设定？对结论有多敏感？ → ⏳待验证

Legend: ✅ 已验证 | ❌ 已否定 | ⏳ 待验证
```

## 💡 洞见汇合 (多实验共识)

| # | 洞见 | 观察 | 决策影响 | 证据 |
|---|------|------|---------|------|
| I1 | 交互历史决定打赏 | pair_gift_mean 重要性是第二名的3倍 | 优先维护交互特征；冷启动是瓶颈 | MVP-0.2 |
| I2 | Baseline 已有较高性能 | Top-1%=56.2%远超30%基准 | 两段式需证明显著提升才值得复杂度 | MVP-0.2 |
| I3 | 模型对比需统一候选集 | MVP-1.1两段式与Baseline在不同数据集训练 | 必须在相同候选集上公平对比 | MVP-1.1 |
| I4 | 分类层和回归层学到不同信号 | Stage1用count特征，Stage2用mean特征 | 两阶段设计有合理性 | MVP-1.1 |
| I5 | 公平对比下直接回归更优 | Direct Top-1%=54.5% vs Two-Stage=35.7% | 保留简单架构，优化特征 | MVP-1.1-fair |
| I6 | p(x)×m(x)乘法组合引入排序噪声 | Two-Stage(35.7%) < 二分类上限(51.7%) | 高稀疏场景慎用两阶段 | MVP-1.1-fair |
| I7 | Two-Stage 在 NDCG@100 上更优 | NDCG@100: 35.9% vs 21.7% (+14.2pp) | 召回用Direct，精排用Two-Stage | MVP-1.1-fair |
| I8 | 延迟校正无效（审计后确认） | 86.3%礼物立即发生，pct_late_50=13.3% | 简单负例处理足够 | MVP-1.2+audit |
| I9 | Two-Stage输的主因是Stage1分类不足 | Oracle_p增益+54.9pp >> Oracle_m+3.1pp | 考虑优化Stage1或采用分工策略 | MVP-1.4 |
| I10 | Stage2在精排场景有明显优势 | gift子集Spearman: Stage2=0.89 > Direct=0.74 | 召回-精排分工 | MVP-1.4 |
| I11 | 多任务学习在极稀疏场景无优势 | Multi PR-AUC=0.165 < Single=0.182 | 极稀疏(<2%)场景慎用多任务 | MVP-1.3 |
| I12 | Simulator Gini可校准，金额分布误差大 | User Gini误差4.9% | Simulator可用于分配策略相对比较 | MVP-0.3 |
| I13 | Greedy分配策略收益远高于Random | Greedy=60,651 vs Random=20,643 (2.94x) | 分配策略对总收益影响显著 | MVP-0.3 |
| I20 | 并发容量能有效建模边际递减 | Revenue/User 从 0.49 降至 0.37 (24.4%) | 高并发损害边际收益 | MVP-4.2 |
| I21 | 低容量设置必要以触发拥挤 | 原 capacity=100 无效果，需降至 15/8/3 | 参数需根据并发量校准 | MVP-4.2 |
| I14 | 凹收益分配无显著优势但公平性改善 | Δ=-1.17%, Gini改善-0.018 | 简化为Greedy+约束 | MVP-2.1 |
| I15 | 软约束冷启动是explore-exploit平衡 | 收益+32%，成功率+263%同时提升 | 冷启动约束本质是有价值的探索 | MVP-2.2 |
| I16 | 硬约束过于激进 | 收益-29%，成功率仅+19% | 避免硬预留，使用软约束λ | MVP-2.2 |
| I17 | V1 Simulator 金额分布严重失真 | P50误差2163%，Mean误差322% | 需V2+校准 | 问题分析 |
| I18 | V2+ 离散档位成功校准 | P50=0%, P90=23%, Mean=27% | Gate-4A PASS | MVP-4.1+ |
| I19 | 离散档位优于连续分布 | V2+ Mean误差27% vs V2 375% | 避免pareto重尾 | MVP-4.1+ |
| I22 | 档位概率是金额校准关键 | tier_probs调整直接影响P50/P90 | 65%概率落在tier≤2才能匹配P50=2 | MVP-4.1+ |
| I23 | 容量参数需根据并发量校准 | capacity=100无效果，降至15/8/3才触发拥挤 | 低估并发时需降低容量 | MVP-4.2 |
| I24 | 高并发场景存在边际递减 | 800用户时Revenue/User下降24.4% | 分配策略需考虑容量约束 | MVP-4.2 |

## ✅ Gate 状态

| Gate | 状态 | 结论 |
|------|------|------|
| Gate-1 估计层 | ✅ 完成 | 直接回归胜出；延迟/多任务无效 |
| Gate-2 分配层 | ✅ 关闭 | Greedy + 软约束冷启动 |
| Gate-3 评估层 | ✅ 关闭 | SNIPS RelErr<10% |
| Gate-4A 金额校准 | ✅ 通过 | V2+ 离散档位: P50=0%, P90=13%, Mean=24% |
| Gate-4B 并发容量 | ✅ 通过 | 边际递减24.4%, 拥挤率68% @800用户 |

## 📐 设计原则

| 原则 | 建议 | 证据 |
|------|------|------|
| 高稀疏场景优先直接回归 | ✅ 做 | MVP-1.1-fair |
| 极稀疏(<2%)场景慎用多任务 | ✅ 做 | MVP-1.3 |
| 模型对比需统一候选集 | ✅ 做 | MVP-1.1 |
| 金额回归用log(1+Y) | ✅ 做 | 文献共识 |
| 稀疏信号用PR-AUC | ✅ 做 | 文献共识 |
| 金额模拟用离散档位 | ✅ 做 | MVP-4.1+ |
| 避免Pareto重尾建模 | ✅ 做 | MVP-4.1+ |
| 容量参数需按并发量校准 | ✅ 做 | MVP-4.2 |
| 高并发场景需考虑边际递减 | ✅ 做 | MVP-4.2 |

## 📋 实验完成度

| Phase | 完成 | MVP |
|-------|------|-----|
| Phase 0 | 3/3 | 0.1, 0.2, 0.3 |
| Phase 1 | 6/7 | 1.1, 1.1-fair, 1.2, 1.2-audit, 1.3, 1.4 |
| Phase 2 | 2/2 | 2.1, 2.2 |
| Phase 3 | 1/1 | 3.1 |
| Phase 4 | 2/7 | 4.1+, 4.2 |
| **总计** | **14/20** | Phase 4 进行中 |

## 🚀 Phase 4 进度

> **Status:** 🔄 进行中 | **Gate-4A/4B 已通过** | **目标:** 解决资源约束的真实建模

| MVP | 名称 | 状态 | 结论 |
|-----|------|------|------|
| 4.1+ | Simulator V2 - 增强版 | ✅ PASS | P50=0%, P90=13%, Mean=24% |
| 4.2 | Simulator V2 - 并发容量 | ✅ PASS | 边际递减24.4%, 拥挤率68% |
| 4.3 | 召回-精排分工 | ⏳ | Top-1% ≥56% |
| 4.4 | 供需匹配/影子价格 | ⏳ | 收益+5% vs Greedy |
| 4.5 | 鲸鱼分散 (b-matching) | ⏳ | 超载率<10% |
| 4.6 | 不确定性排序 (UCB) | ⏳ | CVaR 改善 |
| 4.7 | 多目标生态调度 | ⏳ | Pareto 前沿 |

**详见**: [Phase 4 立项书](./gift_allocation_phase4_charter.md)

## 🔗 导航

| 文件 | 用途 |
|------|------|
| [Roadmap](./gift_allocation_roadmap.md) | MVP规格、进度追踪 |
| [Phase 4 立项](./gift_allocation_phase4_charter.md) | 下一阶段规划 |
| [exp/](./exp/) | 15个实验报告 |
| [results/](./results/) | 数值结果JSON |
