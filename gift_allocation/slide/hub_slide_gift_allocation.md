# Gift Allocation（分配层）— 8min 汇报

> **Topic**: Gift Allocation Hub Overview  \
> **Author**: Viska Wei  \
> **Date**: 2026-01-20  \
> **Language**: 中文

---

## 从"预测更准"到"分配更对"：分配策略是最大杠杆（Greedy ≈ 3× Random）

- **目标**：最大化 *全局长期收益*，同时保护生态（冷启动/公平/容量）
- **现实难点**：极稀疏 + 重尾 + 生态外部性
- **KuaiLive 关键事实**
  - 打赏率：**1.48%**（per-click）
  - 金额：P50/P90/P99 = **2 / 88 / 1488**，Max=56,246
  - 集中度：User Gini **0.942**，Streamer Gini **0.930**
  - 冷启动：**92.2% 主播无打赏**
- **结论先行**：分配策略是最大杠杆（Greedy ≈ 3× Random）

<details>
<summary><b>note</b></summary>

大家好，我这 8 分钟汇报的是 **gift allocation 分配层**：当我们已经能给每个"用户×主播"估一个 EV 的时候，**怎么把高价值用户分配给主播**，才能让"全局收益最大化"，同时不把生态做崩。

先把真实数据的约束讲清楚：KuaiLive 里 **打赏率只有 1.48%**，信号非常稀疏；金额极重尾，P50 是 2 块，但 P99 已经到 1488；集中度也极端，用户侧 Gini 0.942、主播侧 0.930，而且 **92.2% 的主播是冷启动**，几乎没有打赏历史。

所以这不是"把分数排序一下就完事"的问题，而是一个**带约束、带外部性、带生态目标**的在线分配问题。接下来我会用"问题树 + 模块架构 + 关键实验 → 决策"把这一层讲完。

</details>

---

## 核心问题树：分配层到底在解决什么？

```
核心：给定EV预测，如何做"全局最优"的在线分配？
├─ Q1 策略：收益 vs 公平？
│   ├─ 凹收益(边际递减) vs Greedy  → 结论：收益边际不显著
│   └─ 冷启动如何嵌入？           → 结论：软约束有效（探索赚到）
├─ Q2 约束：多约束怎么统一？
│   ├─ 影子价格Primal-Dual        → 结论：当前不如简单规则
│   └─ 鲸鱼分散(b-matching)        → 结论：当前设置不触发约束
├─ Q3 评估：离线怎么可信？
│   └─ Simulator(可控真值)         → V1可用 + V2+更像真实金额
└─ Q4 风险：如何降低线上波动？
    └─ UCB/LCB/CVaR（下一步 Gate-5D）
```

<details>
<summary><b>note</b></summary>

这一页把分配层的工作"拆成一棵树"，保证我们讨论的是同一件事。

第一块是 **策略**：只追收益会导致头部堆叠、生态恶化；只追公平会牺牲效率。所以我们先验证"理论上很优雅"的凹收益边际递减，结果是收益提升并不显著，后面我会给数。

第二块是 **约束**：上线时一定会有容量、冷启动覆盖、头部保护、频控，甚至鲸鱼互斥这类约束。我们尝试了一个统一的 Primal-Dual 影子价格框架，也尝试了鲸鱼分层匹配。但注意，这里"FAIL"不等于没价值，更多是告诉我们：**在当前设置下，它们不是最划算的选择**，以及下一步要怎么改实验设置。

第三块是 **评估**：我们不能直接在线 A/B，所以必须要有 Simulator 的可控真值来验证策略有效性。

最后是 **风险**：重尾场景里均值最优不等于尾部安全，所以我们下一步要做 UCB/LCB/CVaR 的风险控制 Gate。

</details>

---

## 模块架构：可插拔的"EV→分配→评估"闭环

**输入**：候选集合 + EV(u,s) + 状态/约束

```
EV预测(上游)  →  候选集(Candidates)
                 ↓
        Allocation Engine（分配器）
        score = EV - Σ penalty(约束)
                 ↓
    Allocations + Logs(含状态/约束快照)
                 ↓
Evaluation Layer：Simulator V2+（可控真值）
                 ↓
Dashboard：Revenue / ColdStart / Gini / Overload / CVaR
```

**关键设计**
- "策略/约束"解耦：Greedy 是底座，约束是插件
- 评估可控：Simulator 提供真值，策略效果可比较

<details>
<summary><b>note</b></summary>

这一页讲我怎么把分配层做成"能落地、能扩展"的模块，而不是一堆 if-else。

上游会给我们 EV，也就是用户 u 去主播 s 的期望收益。分配器只做一件事：在候选里选一个 s，使得 **score = EV 减去各种约束的惩罚**。

重点是把"策略"和"约束"拆开：
- 策略底座我们先用 Greedy，因为它在模拟器里已经能比 Random 高出接近 3 倍；
- 约束插件包括：冷启动覆盖、头部 cap、频控、容量等。

每一次分配都必须产生日志：包含候选、打分、最终选择、当时容量状态。

评估层用 Simulator 给我们可控真值，可以对比不同策略的效果。这套架构的好处是：你想加一个约束，不需要重写整个策略；你想做风险控制，也只是换 score 的形式。

</details>

---

## Simulator：先把"实验土壤"做对（V1 → V2+）

**为什么要 Simulator**：线上 A/B 成本高；分配策略需要"可控真值"

- **V1 校准（可用）**
  - 财富：Lognormal + Pareto（鲸鱼效应）
  - 结果：Gini 误差 < **5%**；Greedy 收益 ≈ **3×** Random
- **V2+ 增强（更像真实）**：礼物是固定价档 → 用离散档位
  - tiers：1/2/10/52/100/520/1000/1314/5200/13140
  - 结果：P50/P90/Mean 误差均 < **30%**（Gate-4A PASS）

<details>
<summary><b>note</b></summary>

如果没有 Simulator，我们很难判断一个约束到底是"真的提升"，还是"线上偶然波动"。所以我们先做了 Simulator。

V1 的目标不是完美复现，而是先复现两个核心现象：**极端不平等**和**策略差异显著**。我们用 Lognormal + Pareto 混合建财富，用匹配度驱动打赏概率。校准结果是：用户和主播侧的 Gini 误差都控制在 5%以内，而且 Greedy 的收益大约是 Random 的 3 倍。这一条很关键——它证明"分配层是最大杠杆"，不只是模型预测。

但 V1 有个明显问题：金额分布失真，因为真实礼物是固定价格档，不是连续分布。于是我们做了 V2+：直接用离散档位抽取金额，并用财富去调节高档礼物的概率。校准指标用 P50、P90、Mean，最终都在 30%误差以内，通过 Gate-4A。

到这里我们才有了一个可靠的"试验田"，后面所有策略结论都在这个土壤上对比出来。

</details>

---

## 策略实验：凹收益（边际递减）≠ 更高收益

**假设**：Greedy 头部堆叠 → 用凹收益边际递减分散流量

- 决策：$s^* = \arg\max_s g'(V_s) \cdot v_{u,s}$
  - log 型：衰减慢；exp/饱和型：衰减快
- 关键结果（最佳：concave-exp）
  - 收益 **-1.17%**（未达"+10%"门槛）
  - 公平性：Streamer Gini **-0.018**（有改善，但不够大）
- **决策**：关闭"凹收益替代 Greedy"，改走 **Greedy + 显式约束**

<details>
<summary><b>note</b></summary>

这一页讲一个"理论很美、但工程上不划算"的方向：凹收益分配。

直觉是：Greedy 总把高 EV 用户送给头部主播，导致马太效应；如果我们让头部的边际收益递减，后续流量自然会被分散。公式很简单：给每个主播维护累计收益 V，然后每次用 g'(V) 去折扣 EV，选择 g'(V)·v 最大的主播。

我们试了两类凹函数：对数型和饱和型。结果里最好的版本是饱和型 concave-exp：它确实让主播侧 Gini 下降了 0.018，公平性变好；但是收益却下降 1.17%，而且远远没达到我们设定的"至少提升 10%"的收益门槛。

这里我要强调：这不是说凹收益"错了"，而是说在我们的模拟设置下，Greedy 已经很接近最优，凹函数带来的收益提升非常边际，但复杂度上升明显，还可能在规模变大时变差。

因此决策是：**不让凹收益替代 Greedy**，而是保留 Greedy 作为底座，用更可控的"显式约束"来解决生态问题。

</details>

---

## 约束里最值的：软约束冷启动（探索反而赚到）

**痛点**：新主播无历史 → Greedy 永远不选 → 生态断层

- 方法：拉格朗日软约束（自动调节强度）
  - $score = EV - \lambda\cdot violation$
  - $\lambda \leftarrow [\lambda + \eta(violation-b)]_+$
- 结果（Soft Cold-Start）
  - Revenue：**+32%**（41,594 → 54,882）
  - Cold-start success：**+263%**（16.8% → 61.1%）
  - Gini：+0.7%（可接受）
- **决策**：采用 **Greedy + Soft Cold-Start**（推荐 $\lambda_{init}=0.5$，min\_allocation=10）

<details>
<summary><b>note</b></summary>

如果说上一页是"凹收益不够值"，那这一页是我们在分配层最确定的一个正向结论：**软约束冷启动**。

冷启动为什么难？因为新主播没有历史，EV 估计不稳定，Greedy 在不确定性下会一直吃老主播的"确定性收益"，新主播永远没曝光。

我们用的不是硬预留，而是软约束：在目标里加一项惩罚，违反冷启动覆盖就涨价，也就是让对偶变量 λ 自己学出来"多强的约束才刚刚好"。

结果非常反直觉：Soft Cold-Start 不但没损失收益，反而 **收益提升 32%**，冷启动成功率提升 **263%**。解释也很直观：这其实是在做探索——我们被迫把一部分流量给新主播，结果发现了被埋没的高潜主播；而硬约束因为太激进，反而显著损失收益。

所以这里的决策很明确：上线的默认策略应该是 **Greedy + 软约束冷启动**，并把 λ=0.5、min_allocation=10 作为推荐配置。

</details>

---

## "Fail ≠ 没价值"：影子价格 & 鲸鱼分散的真实结论

### A) 影子价格（Primal-Dual 多约束统一框架）
- 目标：统一处理容量/冷启/头部/鲸鱼/频控
- 结果：Revenue **+2.74%**（< +5% 门槛），容量满足率 **82.8%**（<90% 门槛）
- 对照：Greedy+Rules **+4.36%** 更好
- **结论**：框架方向对，但 **惩罚函数/收敛性** 是瓶颈 → 先保留简单规则

### B) 鲸鱼分层匹配（b-matching）
- 策略：鲸鱼层每主播最多 k 个鲸鱼，再 Greedy 填充
- 结果：Gini **0.912 不变**，k=1~5 全相同
- 真实原因：Top1% 鲸鱼 **太稀疏**（100 鲸鱼 / 500 主播 = 0.2/主播），约束不触发
- **结论**：不是算法没用，而是 **实验设置没把系统推到"拥挤态"**（下一步：Top5% + 降容量重试）

<details>
<summary><b>note</b></summary>

这一页我想专门处理两类"看起来失败，但信息含量很高"的实验：影子价格和鲸鱼分散。

先说影子价格。我们的动机非常合理：线上约束会越来越多，用 if-else 叠规则会失控，所以想用 Primal-Dual 的统一框架，把每个约束都变成一个"价格" λ，分配时从 EV 里扣掉惩罚。实验结果是：收益提升 2.74%，但没达到我们预设的 5%门槛；更关键的是容量满足率只有 82.8%，低于 90%。而且简单的 Greedy+Rules 反而能做到 4.36% 的收益提升。

这里"FAIL"的含义不是"影子价格不行"，而是：在当前惩罚设计和收敛设置下，它还没打赢更简单的方案。真正的教训是：**惩罚函数怎么写、λ 怎么收敛**，决定了统一框架能不能落地。短期决策就是先保留 Greedy+Rules。

再说鲸鱼分散。我们做了鲸鱼分层匹配，给每个主播设一个 k 的鲸鱼上限，想降低集中度。结果 Gini 完全不变，k 从 1 到 5 都一样。原因也很清楚：Top1% 鲸鱼只有 100 个，主播 500 个，平均每个主播 0.2 个鲸鱼，k=1 的约束根本不触发。也就是说，这不是 b-matching 算法的问题，而是实验没有把系统推到"鲸鱼拥挤"场景。

因此正确的结论是：鲸鱼分散需要 **扩大鲸鱼定义到 Top5%**、或者 **降低容量制造拥挤**，再重测；当前设置下先不引入分层复杂度。

</details>

---

## 当前推荐方案 & 下一步 Gate（你现在可以上线什么）

**当前推荐（可落地版）**
- EV 预测（上游）
- 分配：**Greedy + Rules + Soft Cold-Start($\lambda$=0.5)**
- 评估：**Simulator V2+（离散档位）**

**护栏指标（上线必看）**
- Revenue / Rev per user
- Cold-start success & coverage
- Streamer Gini / Top share
- Overload / capacity violate
- CVaR@5%（尾部风险）

**下一步（Phase 5）**
- 🔴 Gate-5D：风险控制（UCB/LCB/CVaR）→ 降波动、保尾部
- 🟡 鲸鱼分散 5.3'：Top5% + 降容量重试
- 🟢 5.5：多目标 Pareto 前沿 → 护栏定阈值

**必须补齐的日志字段**
- capacity_at_alloc、lambda_values、is_whale、uncertainty_score

<details>
<summary><b>note</b></summary>

最后我用一页把"现在能上线什么"和"下一步做什么"说清楚。

现在这层的推荐方案是：上游继续提供 EV，我们在分配层用 **Greedy 作为底座**，叠加一组简单规则做护栏，再加上已经验证最有效的 **软约束冷启动**，λ 推荐 0.5。评估层用 V2+ 的 Simulator 做真值对比。

上线时我们不只盯 Revenue，还必须盯护栏：冷启动成功率、主播侧 Gini、容量超载，以及重尾场景下最重要的 **CVaR@5%**——也就是最差 5% 情况的收益，避免"均值没掉但尾部崩了"。

下一步的 Gate 很明确：第一优先级是 **Gate-5D 风险控制**，用 UCB/LCB 或 CVaR 做更稳的排序；第二是把鲸鱼分散在"更真实的拥挤态"里重跑；第三是做多目标 Pareto 前沿，把生态权衡显式化，用来定上线护栏阈值。

最后提醒一句：日志里必须补齐分配时容量状态、λ 快照、鲸鱼标识和不确定性分数。到这里，gift allocation 分配层的闭环就完整了。

</details>

---

<details>
<summary><b>备忘：8分钟口播节奏建议</b></summary>

| 页数 | 时长 | 内容 |
|------|------|------|
| 1 | 50s | 问题+关键事实 |
| 2 | 55s | 问题树 |
| 3 | 55s | 架构 |
| 4 | 60s | Simulator |
| 5 | 55s | 凹收益结论 |
| 6 | 60s | 冷启动软约束 |
| 7 | 75s | 影子价格+鲸鱼分散（"Fail≠没价值"） |
| 8 | 55s | 推荐方案+Roadmap |

</details>
