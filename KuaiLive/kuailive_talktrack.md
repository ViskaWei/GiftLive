# KuaiLive 汇报文稿（补充版）

> 用途：给主管口头汇报时的“连贯叙事”，不依赖逐页念 PPT。

---

## A. 8页精简版（5–8分钟）讲稿

### 开场（20秒）
我们要解决的不是“把一个主播做爆”，而是**在真实直播生态约束下最大化长期全局收益**：短期 Revenue、用户留存/满意度、主播生态健康三者同时兼顾。KuaiLive 的价值在于它具备动态候选集、多行为序列、负反馈，能让我们离线模拟直播推荐/分配的关键难点。

### 关键事实（2分钟）
我做了全方位 EDA 后，有 3 个会直接改变后续建模与策略设计的事实：
1) **打赏极“即时”**：90%+ 的打赏发生在 session 前 10% 时间窗口——这决定了我们的特征工程、触发策略、分配动作都必须围绕“首10%”布局。
2) **付费高度专一**：付费用户几乎只给 Top1 主播打赏——这意味着“把大哥分散给陌生主播”很难立刻奏效，分配层必须做分层：保底满足偏好 + 受控探索。
3) **极稀疏+重尾**：整体 per-click gift 约 1.5%，Top 1% 用户贡献约 60% 收益——评估必须同时看 Top-1% capture 与 NDCG，否则会发生“只追头部/只追细排”的失真。

### 关键否定（40秒）
我还把两个常见“看起来对、但在这个数据上不成立”的方向关掉了：
- **延迟反馈复杂校正**：延迟中位数是 0，复杂加权反而让校准变差。
- **两段式(p×m)当默认主路线**：在公平对比下，直接回归在 Top-1% capture 更强；两段式只在 NDCG@100 上更好，因此它应该是“细排专项”，不是主干。

### 方案（2分钟）
我建议把系统拆成闭环：
- **预测层**（session）：多任务输出短期 EV + 满意度 proxy（停留/互动）+ 留存 proxy（复访）。
- **分配层**（全局）：引入凹收益 + 影子价格，显式处理资源约束（大哥稀缺、主播承接上限）与生态护栏（集中度/覆盖）。
- **评估层**：先做 Simulator（校准即时、重尾、专一），再用 OPE（IPS/DR）在可控方差下比较策略。

### 下一步与需要拍板（1分钟）
两周内最短闭环：Week1 把估计层做成可用（特征+ablation+三件套指标）；Week2 做 simulator V1 + 凹收益分配原型。
我需要你拍板三件事：目标函数权重（Revenue/留存/生态）、是否能有小比例随机桶（支撑 OPE）、以及主播承接上限/用户频控的业务口径。

---

## B. 20页详细版（15–25分钟）讲稿

### B1. 问题重述（1分钟）
直播打赏优化的难点不在“预测谁会送礼”这么简单，而在于：
- 信号极稀疏、重尾、高方差（少数大额贡献绝大部分）
- 候选集随时间变化（动态在播）
- 线上决策是资源约束（大哥稀缺、主播承接上限）
- 目标必须长期（只追短期 GMV 会伤留存与生态）

因此最可控的工程解法是：**估计层把“可组合的价值”预测出来，决策层在约束下做全局最优分配，评估层用 simulator/OPE 保证迭代可靠**。

### B2. EDA：把“事实”变成“决策杠杆”（6–8分钟）
我在 EDA 里重点找“会改变决策”的结构性规律：
1) 即时性：首礼时间相对 session 时长的分布极度左偏，90%+ 在前 10%。这意味着：
   - 工程侧：需要“首10%窗口”实时特征与触发
   - 模型侧：应该用 session 粒度，并把 early-window 特征单独建模
2) 人群增量：存在 17.6% 高观看低付费用户。直觉上这是“可转化”的最大池子之一，因为他们已经贡献了注意力。
3) 供给增量：18.2% 高吸引低变现主播。对这类主播提升转化效率，可能带来比“挪头部存量”更健康的增量。
4) 付费专一：gift loyalty P50=100%。这告诉我们：
   - 需要强 pair 特征（用户-主播关系）
   - 分配层必须分层：对强专一用户以满足为主，对非专一或高观看低付费做探索为主
5) 重尾与集中：Gini≈0.94、Top1% user≈60%。评估不能只用 MSE；排序必须看头部捕获与细排质量两个维度。

### B3. 估计层：预测什么（而不是只预测什么最容易）（4–6分钟）
我建议把“预测层输出”设计成能直接服务分配层的结构：
- short-term：EV_gift（期望打赏金额）
- medium-term：满意度 proxy（停留/互动）
- longer-term：留存 proxy（次日复访）

模型方面：
- 主干先用 direct regression（高稀疏下更稳定），并把“统一候选集的公平对比”作为硬原则。
- two-stage 仅作为“金主内部细排”备选，因为它在 NDCG@100 更强。
- 延迟校正不做主线，工程上用“截断+回补”。

### B4. 决策层：从排序到资源分配（4–6分钟）
如果我们只最大化 EV，总会把资源堆到少数头部主播与少数大哥偏好上，带来生态与体验风险。
我的方案是：
- 对主播累计价值 V_s 施加凹收益 g(V_s)（边际递减），并维护影子价格 λ_s=g'(V_s)。
- 每次分配选择最大化：预测价值 - 影子价格 - 约束惩罚。
- 把三类约束显式化：用户频控、主播承接上限、生态护栏（集中度阈值/覆盖率）。

这套机制的好处是：可解释、可调参、可加入业务规则，且天然避免“过度集中”。

### B5. 评估层：让策略迭代可控（2–4分钟）
离线回放在稀疏+重尾下方差巨大，而且策略会改变曝光分布。
因此我们需要：
- Simulator V1：先能复现三件事（即时/重尾/专一），用来扫分配层参数与约束强度。
- OPE：在带 propensity 的日志上验证 IPS/DR 的 bias/variance，再尝试在真实日志上应用。

### B6. Roadmap 与资源诉求（2分钟）
两周内我能交付一个可跑通的闭环原型：可用预测、可控分配、可复现实验。
需要你确认：目标权重、是否能有随机桶、以及承接上限/频控口径。

---

## C. 主管可能追问（备答要点）

1) **为什么强调“凹收益”？会不会损 GMV？**
- 凹收益不是为了公平，而是为了处理边际递减与系统稳定性。我们会用 simulator 给出“约束强度—收益—生态”的曲线，找工作点。

2) **两段式不是常规做法吗？为什么不用？**
- 我不反对两段式，但必须在统一候选集下公平对比。现有结果显示：它在 Top-1% capture 不占优，只在 NDCG@100 上占优，所以把它定位为细排专项更合适。

3) **没有留存字段怎么做长期？**
- 先用可观测 proxy：次日复访、停留、跳出率等。目标是先把闭环跑通，再逐步替换为更强的长期指标。

4) **付费专一这么强，还能做分配吗？**
- 可以，但要分层：对强专一用户“保底满足”，对高观看低付费用户/非专一用户“探索转化”，增量主要来自转化效率提升而不是强行迁移大哥。
