# GiftLive 系统全景 — 5min 开场汇报

> **Topic**: GiftLive System Overview (Data → Estimate → Allocation → Evaluation)  \
> **Author**: Viska Wei  \
> **Date**: 2026-01-20  \
> **Language**: 中文

---

## 从数据到决策：一个完整的直播打赏优化系统

- **核心问题**：如何在直播场景下最大化长期收益，同时保护生态？
- **数据现实（KuaiLive）**
  - 打赏率：**1.48%**（per-click，极稀疏）
  - 金额：P50 / P90 / P99 = **2 / 88 / 1488**（极重尾）
  - 集中度：User Gini **0.942**，Streamer Gini **0.926**
  - 冷启动：**92.2% 主播无打赏历史**
- **结论先行**：分配策略是最大杠杆（Greedy ≈ 3× Random）；预测更准的边际收益有限

<details>
<summary><b>note</b></summary>

大家好，今天用 5 分钟给大家介绍 **GiftLive 系统的全景**——这是一个从数据到决策的完整直播打赏优化系统。

我先把数据现实讲清楚：在 KuaiLive 数据集里，**打赏率只有 1.48%**，极其稀疏；金额分布极重尾，P50 是 2 块，但 P99 高达 1488；而且收入极度集中，用户侧 Gini 0.942，主播侧 0.926。更关键的是，**92.2% 的主播几乎没有打赏历史**——冷启动是结构性问题。

在这样的数据现实下，我们做实验后发现一个核心结论：**分配策略是最大杠杆**——从 Random 切到 Greedy，收益翻 3 倍；但预测模型从 Ridge 换成更复杂模型，提升只有 5% 左右。这就是为什么我们把系统分成四层来做。

</details>

---

## 四层系统架构：Data → Estimate → Allocation → Evaluation

```
用户请求
    ↓
┌─────────────────────────────────────────────────────┐
│ 0️⃣ 数据层: KuaiLive                                 │
│    - 规模: 2.4万用户 × 45万主播 × 1160万直播间       │
│    - 特性: 动态候选集 + 多行为序列 + 负反馈          │
│    - 信号: 90.36% 打赏发生在 session 前 10%          │
└─────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────┐
│ 1️⃣ 估计层: Direct Regression                        │
│    - 模型: Ridge 回归 raw Y（不是 log(1+Y)）         │
│    - 特征: 用户-主播交互历史为核心（20 维 Strict）   │
│    - 输出: 期望收益 EV(u,s)                          │
│    - 成果: RevCap@1% = 51.4%                        │
└─────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────┐
│ 2️⃣ 分配层: Greedy + 软约束                          │
│    - 策略: argmax EV(u,s) + λ·冷启动 bonus          │
│    - 参数: λ=0.5, min_alloc=10                      │
│    - 效果: 收益 +32%, 新主播成功率 +263%             │
└─────────────────────────────────────────────────────┘
    ↓
┌─────────────────────────────────────────────────────┐
│ 3️⃣ 评估层: SNIPS OPE                               │
│    - 方法: Self-Normalized IPS                      │
│    - 要求: 探索率 ≥ 0.3, 日志量 ≥ 5000              │
│    - 精度: RelErr < 10%                             │
└─────────────────────────────────────────────────────┘
```

- **关键设计**：四层解耦，每层可独立迭代；评估层提供闭环反馈

<details>
<summary><b>note</b></summary>

这是系统的四层架构，从数据到评估形成闭环：

**数据层**用的是 KuaiLive——快手首个公开的直播推荐数据集。规模是 2.4 万用户、45 万主播、1160 万直播间。它有三个核心特性：动态候选集（某一时刻哪些房间在播）、多行为序列（click/comment/like/gift）、以及负反馈数据。我们在 EDA 中发现一个关键信号：**90.36% 的打赏发生在 session 前 10% 时间内**——这意味着首屏/首段时间是决策的主窗口。

**估计层**的任务是预测"这个用户去这个主播，会打赏多少钱"。我们尝试了很多方案后，发现 **Ridge 回归 + raw Y** 是最优的。注意不是 log(1+Y)——因为 log 会把 10 元和 1000 元的差距压缩，丢失大哥信号。当前成果是 RevCap@1%=51.4%，意味着 Top 1% 预测能捕获一半以上收入。

**分配层**拿到 EV 之后，决定把用户分配给谁。核心策略是 **Greedy + 软约束冷启动**。软约束的意思是：对冷启动主播给一个 bonus，力度由 λ 自动学习。结果非常反直觉——收益不仅没损失，反而 **提升 32%**，新主播成功率提升 263%。这其实是在做探索：被迫给新主播流量后，发现了被埋没的高潜主播。

**评估层**用 SNIPS（自归一化重要性采样）做离线策略评估。SNIPS 能把相对误差控制在 10% 以内，前提是行为策略保持 ε≥0.3 探索率、日志量 ≥5000。

</details>

---

## 每层核心洞见：从数据特性到设计原则

| 层 | 核心洞见 | 数据证据 | 设计决策 |
|----|---------|---------|---------|
| **数据层** | 打赏是"即时冲动" | 90.36% 发生在前 10% | 首窗口特征是主杠杆 |
| **数据层** | 冷启动是结构性问题 | 92.2% 主播无历史 | 禁止 5-core 过滤 |
| **估计层** | Raw Y >> Log Y | RevCap +39.6% | 预测目标用 raw Y |
| **估计层** | 历史打赏是最强信号 | pair_hist 系数 0.194 | 重点挖掘 pair 特征 |
| **分配层** | 分配策略是最大杠杆 | Greedy ≈ 3× Random | 分配优先，预测次之 |
| **分配层** | 探索能带来收益 | 软约束 +32% revenue | 采用软约束冷启动 |
| **评估层** | SNIPS 控制方差 | RelErr 0.57%-9.97% | 主 OPE 方法用 SNIPS |

<details>
<summary><b>note</b></summary>

这张表总结了每层最重要的洞见，以及它如何影响设计决策。

数据层有两个关键发现：第一，**打赏是即时冲动行为**，90% 以上发生在用户进入直播间的前 10% 时间——这意味着首窗口特征和触发设计是主杠杆；第二，**冷启动是结构性问题**，92% 的主播几乎没有打赏历史，所以我们不能用传统的 5-core 过滤。

估计层最重要的发现是 **raw Y 比 log(1+Y) 好 39.6%**。直觉上 log 变换处理长尾很合理，但它把 10 元和 1000 元的差距从 100 倍压缩成 3 倍，丢失了大哥信号。另外，**历史打赏特别是 pair 级别的历史**是最强信号——这也意味着首次打赏很难预测。

分配层最重要的发现是 **策略差异远大于模型差异**。Greedy 比 Random 收益翻 3 倍，但预测模型从 Ridge 换成 LightGBM 提升只有 5%。另外，软约束冷启动不仅没损失收益，反而带来 32% 提升——探索能发现被埋没的高潜主播。

评估层确认了 **SNIPS 是高方差场景的首选 OPE 方法**，相对误差可控在 10% 以内。

</details>

---

## 当前可落地方案 & 下一步 Gate

**当前推荐（可落地版）**
- **估计层**：Ridge + raw Y + Strict 20 特征 → RevCap@1%=51.4%
- **分配层**：Greedy + Soft Cold-Start (λ=0.5) → +32% 收益
- **评估层**：Simulator V2+ (离散档位) + SNIPS (ε=0.3, n≥5000)

**护栏指标（上线必看）**
- Revenue / Rev per user
- Cold-start success & coverage
- Streamer Gini / Top share
- Overload / capacity violate
- CVaR@5%（尾部风险）

**下一步（Phase 5）**
- 🔴 **Gate-5D**：风险控制（UCB/LCB/CVaR）→ 降波动、保尾部
- 🔴 **P0**：线上日志系统添加 propensity 字段
- 🟡 鲸鱼分散 5.3'：Top5% + 降容量重试
- 🟢 多目标 Pareto 前沿 → 护栏定阈值

<details>
<summary><b>note</b></summary>

最后一页把"现在能上线什么"和"下一步做什么"说清楚。

当前可落地的方案是：
- 估计层用 **Ridge + raw Y**，20 个 Strict 特征，RevCap 达到 51.4%
- 分配层用 **Greedy + 软约束冷启动**，λ 推荐 0.5，收益提升 32%
- 评估层用 **Simulator V2+** 做策略对比，加上 **SNIPS** 做离线策略评估

上线时必须盯的护栏：不只是 Revenue，还有冷启动覆盖、主播侧 Gini、容量超载，以及重尾场景下最重要的 **CVaR@5%**——也就是最差 5% 情况的收益，避免"均值没掉但尾部崩了"。

下一步有两个高优先级任务：
1. **Gate-5D 风险控制**：用 UCB/LCB 或 CVaR 做更稳的排序，降低线上波动
2. **日志系统改造**：必须添加 propensity 字段，否则 SNIPS 无法在线上使用

中优先级是把鲸鱼分散在更真实的"拥挤态"里重跑；低优先级是做多目标 Pareto 前沿来定护栏阈值。

到这里，GiftLive 的四层系统闭环就介绍完了。谢谢大家！

</details>

---

## 备忘：5分钟口播节奏建议

| 页数 | 时长 | 内容 |
|------|------|------|
| 1 | 60s | 核心问题 + 数据现实 + 结论先行 |
| 2 | 80s | 四层系统架构 + 每层核心 I/O |
| 3 | 60s | 每层核心洞见表（快速过） |
| 4 | 60s | 当前方案 + 护栏 + 下一步 |

**总计**：约 4分20秒，留 40 秒 buffer 处理提问或强调重点
